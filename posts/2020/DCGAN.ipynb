{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "aliases:\n",
    "- /GANs/2020/11/16/DCGAN\n",
    "badges: true\n",
    "categories:\n",
    "- GANs\n",
    "date: '2020-11-16'\n",
    "description: \"A beginner-friendly tutorial on DCGAN with PyTorch to generate Fake\\\n",
    "  \\ celebrity images with CelebA\\_dataset.\"\n",
    "image: https://raw.githubusercontent.com/aniketmaurya/ml-resources/master/images/dcgan-vector-arithmetic.png\n",
    "keywords: GANs, PyTorch, deep learning, python\n",
    "output-file: 2020-11-16-dcgan.html\n",
    "title: \"DCGAN Tutorial\\u200A-\\u200AGenerate Fake Celebrity image\"\n",
    "toc: true\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/aniketmaurya/blog/blob/master/_notebooks/2020-11-16-DCGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gDtV9cRRgBxs"
   },
   "source": [
    "> This article can be opened as Jupyter Notebook to train DCGAN on CelebA dataset to generate fake celebrity images.\n",
    "\n",
    "{{< video https://github.com/aniketmaurya/pytorch-gans >}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vNMrpS4lf4It"
   },
   "source": [
    "# What is DCGAN?\n",
    "DCGAN (Deep Convolutional Generative Adversarial Network) is created by Alec Radford, Luke Metz and Soumith Chintala in 2016 to train Deep Generative Adversarial Networks. In the [DCGAN paper](https://arxiv.org/abs/1511.06434), the authors trained the network to produce fake faces of celebrities and fake bedroom images.\n",
    "\n",
    "The architecture consists of two networks - Generator and Discriminator. Generator is the heart of GANs. It produces real looking fake images from random noise. \n",
    "\n",
    "Discriminator wants the real and fake image distributions to be as far as possible while the Generator wants to reduce the distance between the real and fake image distribution.\n",
    "In simple words, the Generator tries to fool the Discriminator by producing real looking images while the Discriminator tries to catch the fake images from the real ones.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VpphkP6sUV6Y"
   },
   "source": [
    "| ![Picture from paper](https://raw.githubusercontent.com/aniketmaurya/ml-resources/master/images/dcgan-vector-arithmetic.png) |\n",
    "| :-: |\n",
    "| *Vector arithmetic for visual concepts. Source: Paper* |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6F7vn3fPqwB-"
   },
   "source": [
    "# Training details from the paper\n",
    "**Preprocessing**: Images are scaled to be in range of tanh activation, [-1, 1].\n",
    "Training was done with a mini-batch size of 128 and Adam optimizer with a learning rate of 0.0002.\n",
    "All the weights initialised with Normal distribution $\\mu(0, 0.02)$.\n",
    "\n",
    "**Authors guidelines:**\n",
    "- All the pooling layers are replaced with strided convolutions in the discriminator and [fractional strided convolution](https://deepai.org/machine-learning-glossary-and-terms/fractionally-strided-convolution) in the discriminator.\n",
    "- No fully-connected or pooling layers are used.\n",
    "- Batchnorm used in both Generator and Discriminator\n",
    "- ReLu activation is used for generator for all the layers except the last layer which uses tanh\n",
    "- Discriminator uses LeakyReLu for all the layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "92kRSmHvyLXo"
   },
   "source": [
    "In this post I will train a GAN to generate celebrity faces.\n",
    "## Generator\n",
    "A Generator consists Transposed Convolution, Batch Normalisation and activation function layer.\n",
    "- First the random noise of size 100 will be reshaped to 100x1x1 (channel first in PyTorch).\n",
    "- It is passed through a Transposed CNN layer which upsamples the input Tensor.\n",
    "- Batch Normalisation is applied.\n",
    "- If the layer is not the last layer then ReLu activation is applied else Tanh.\n",
    "\n",
    "First channel size is 1024 which is then decreased block by block to 3 for RGB image. Finally we will get a 3x64x64 Tensor which will be our image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wstmr9Xha004"
   },
   "source": [
    "| ![Generator architecture](https://raw.githubusercontent.com/aniketmaurya/ml-resources/master/images/dcgan-gen-arch.png) |\n",
    "|:--:|\n",
    "| *Generator architecture from the Paper* |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "REP3NLbnd4m9",
    "outputId": "b15e6544-d1f2-4ad7-99a9-b31112a032d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f7b8cf9e6c0>"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | code-fold: true\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torch.optim import Adam\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iBZ9as1mwS_i"
   },
   "outputs": [],
   "source": [
    "# | code-fold: true\n",
    "def show_tensor_images(image_tensor, num_images=25, size=(3, 64, 64)):\n",
    "    \"\"\"\n",
    "    Function for visualizing images: Given a tensor of images, number of images, and\n",
    "    size per image, plots and prints the images in an uniform grid.\n",
    "    \"\"\"\n",
    "    image_tensor = (image_tensor + 1) / 2\n",
    "    image_unflat = image_tensor.detach().cpu()\n",
    "    image_grid = make_grid(image_unflat[:num_images], nrow=5)\n",
    "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YhKtTQuuwXw4"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, in_channels=3, z_dim=100):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.gen = nn.Sequential(\n",
    "            self.create_upblock(z_dim, 1024, kernel_size=4, stride=1, padding=0),\n",
    "            self.create_upblock(1024, 512, kernel_size=4, stride=2, padding=1),\n",
    "            self.create_upblock(512, 256, kernel_size=4, stride=2, padding=1),\n",
    "            self.create_upblock(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            self.create_upblock(\n",
    "                128, 3, kernel_size=4, stride=2, padding=1, final_layer=True\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def create_upblock(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        kernel_size=5,\n",
    "        stride=2,\n",
    "        padding=1,\n",
    "        final_layer=False,\n",
    "    ):\n",
    "        if final_layer:\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(\n",
    "                    in_channels, out_channels, kernel_size, stride, padding, bias=False\n",
    "                ),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.Tanh(),\n",
    "            )\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels, out_channels, kernel_size, stride, padding, bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "\n",
    "    def forward(self, noise):\n",
    "        \"\"\"\n",
    "        noise: random vector of shape=(N, 100, 1, 1)\n",
    "        \"\"\"\n",
    "        assert len(noise.shape) == 4, \"random vector of shape=(N, 100, 1, 1)\"\n",
    "\n",
    "        return self.gen(noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8eA7T6DgNEWN"
   },
   "source": [
    "## Discriminator\n",
    "The architecture of a Discriminator is same as that of a normal image classification model. It contains Convolution layers, Activation layer and BatchNormalisation. In the DCGAN paper, strides are used instead of pooling to reduce the size of a kernel. Also there is no Fully Connected layer in the network. Leaky ReLU with leak slope 0.2 is used.\n",
    "\n",
    "The Discriminator wants to predict the fake images as fake and real images as real. On the other hand the Generator wants to fool Discriminator into predicting the fake images produced by the Generator as real."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cwMhI4ima2tT"
   },
   "source": [
    "| ![Gan objective](https://raw.githubusercontent.com/aniketmaurya/machine_learning/master/blog_files/2020-11-16-DCGAN/gan-objective.png) |\n",
    "| :-: |\n",
    "| *Source: deeplearning.ai GANs Specialisation* |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NAg4S2d-0G2_"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, im_chan=3, hidden_dim=32):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            self.make_disc_block(im_chan, hidden_dim),\n",
    "            self.make_disc_block(hidden_dim, hidden_dim * 2),\n",
    "            self.make_disc_block(hidden_dim * 2, hidden_dim * 4, stride=1),\n",
    "            self.make_disc_block(hidden_dim * 4, hidden_dim * 4, stride=2),\n",
    "            self.make_disc_block(hidden_dim * 4, 1, final_layer=True),\n",
    "        )\n",
    "\n",
    "    def make_disc_block(\n",
    "        self,\n",
    "        input_channels,\n",
    "        output_channels,\n",
    "        kernel_size=4,\n",
    "        stride=2,\n",
    "        final_layer=False,\n",
    "    ):\n",
    "        if not final_layer:\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(input_channels, output_channels, kernel_size, stride),\n",
    "                nn.BatchNorm2d(output_channels),\n",
    "                nn.LeakyReLU(0.2),\n",
    "            )\n",
    "        else:\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(input_channels, output_channels, kernel_size, stride)\n",
    "            )\n",
    "\n",
    "    def forward(self, image):\n",
    "        disc_pred = self.disc(image)\n",
    "        return disc_pred.view(len(disc_pred), -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5dTxzmHwqYkF"
   },
   "source": [
    "Define learning rate, z_dim (noise dimension), batch size and other configuration based on the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mxgVNyAGbVXr"
   },
   "outputs": [],
   "source": [
    "# | code-fold: true\n",
    "# Configurations are from DCGAN paper\n",
    "z_dim = 100\n",
    "batch_size = 128\n",
    "lr = 0.0002\n",
    "\n",
    "beta_1 = 0.5\n",
    "beta_2 = 0.999\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UsbbSOyLLRNg"
   },
   "outputs": [],
   "source": [
    "# | code-fold: true\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find(\"BatchNorm\") != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "\n",
    "gen = Generator().to(device)\n",
    "disc = Discriminator().to(device)\n",
    "\n",
    "\n",
    "gen_optimizer = Adam(gen.parameters(), lr, betas=(beta_1, beta_2))\n",
    "disc_optimizer = Adam(disc.parameters(), lr, betas=(beta_1, beta_2))\n",
    "\n",
    "\n",
    "gen = gen.apply(weights_init)\n",
    "disc = disc.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cy450yqaMSaa"
   },
   "outputs": [],
   "source": [
    "# | code-fold: true\n",
    "# You can tranform the image values to be between -1 and 1 (the range of the tanh activation)\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(64),\n",
    "        transforms.CenterCrop(64),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    datasets.CelebA(\".\", download=True, transform=transform),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZFXZf47aqWYS"
   },
   "source": [
    "# Training Loop\n",
    "Binary Crossentropy loss, $J(\\theta) = -1/m \\sum[y^i logh[X^i, \\theta] + (1-y^i)log(1-h[X^i, \\theta)]$, for training DCGAN.\n",
    "\n",
    "## Discriminator Loss\n",
    "As the discriminator wants to increase the distance between Generated and Real distribution, we will train it to give high loss when the generated images is classified as real or when real images are classified as fake.\n",
    "\n",
    "## Generator Loss\n",
    "The BCE loss for Generator will be high when it fails to fool the Discriminator. It will give high loss when the generated image is classified as fake by the discriminator. *Note that the Generator never know about real images.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2z3LKSA9bV9v"
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "display_step = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KA_vGIz6bWNf"
   },
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "cur_step = 0\n",
    "mean_generator_loss = 0\n",
    "mean_discriminator_loss = 0\n",
    "for epoch in range(n_epoch):\n",
    "    for real, _ in tqdm(dataloader):\n",
    "        real = real.to(device)\n",
    "\n",
    "        # update the discriminator\n",
    "        # create fake images from random noise\n",
    "        disc_optimizer.zero_grad()\n",
    "        noise = torch.randn(cur_batch_size, z_dim, 1, 1, device=device)\n",
    "        fake_images = gen(noise)\n",
    "        logits_fake = disc(fake_images.detach())\n",
    "        logits_real = disc(real)\n",
    "\n",
    "        disc_loss_fake = criterion(fake_logits, torch.zeros_like(loss_fake))\n",
    "        disc_loss_real = criterion(real_logits, torch.ones_like(logits_real))\n",
    "\n",
    "        disc_loss = (disc_loss_fake + disc_loss_real) / 2\n",
    "        # Keep track of the average discriminator loss\n",
    "        mean_discriminator_loss += disc_avg_loss.item() / display_step\n",
    "\n",
    "        disc_loss.backward(retain_graph=True)\n",
    "        disc_optimizer.step()\n",
    "\n",
    "        # Update the generator\n",
    "        gen_optimizer.zero_grad()\n",
    "        noise = torch.randn(cur_batch_size, z_dim, 1, 1, device=device)\n",
    "        fake_images = gen(noise)\n",
    "        logits_fake = disc(fake_images)\n",
    "\n",
    "        gen_loss = criterion(logits_fake, torch.ones_like(logits_fake))\n",
    "        gen_loss.backward()\n",
    "        gen_optimizer.step()\n",
    "\n",
    "        # Keep track of the average generator loss\n",
    "        mean_generator_loss += gen_loss.item() / display_step\n",
    "\n",
    "        ## Visualization code ##\n",
    "        if cur_step % display_step == 0 and cur_step > 0:\n",
    "            print(\n",
    "                f\"Step {cur_step}: Generator loss: {mean_generator_loss}, discriminator loss: {mean_discriminator_loss}\"\n",
    "            )\n",
    "            show_tensor_images(fake_images)\n",
    "            show_tensor_images(real)\n",
    "            mean_generator_loss = 0\n",
    "            mean_discriminator_loss = 0\n",
    "        cur_step += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gvsRQWaqSbpj"
   },
   "source": [
    "# References\n",
    "[1.] [Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks](https://arxiv.org/pdf/1511.06434.pdf)\n",
    "\n",
    "[2.] [Generative Adversarial Networks (GANs) Specialization](https://www.coursera.org/specializations/generative-adversarial-networks-gans)\n",
    "\n",
    "[3.] [DCGAN Tutorial - PyTorch Official](https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html)\n",
    "\n",
    "I would highly recommend [GANs Specialization](https://www.coursera.org/specializations/generative-adversarial-networks-gans) on Coursera if you want to learn GANs in depth.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "if4Ub25xgRuA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "2020-11-16-DCGAN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
